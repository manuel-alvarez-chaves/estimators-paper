{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import ast\n",
    "from utils import get_logger\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.special import gamma, digamma\n",
    "from scipy.integrate import nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'base_evaluator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ac140439\\Documents\\SimTech\\Projects\\Information Theory\\data_evaluation\\bin_entropy_dev.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ac140439/Documents/SimTech/Projects/Information%20Theory/data_evaluation/bin_entropy_dev.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevaluators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbin_evaluators\u001b[39;00m \u001b[39mimport\u001b[39;00m EvaluatorBIN\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ac140439/Documents/SimTech/Projects/Information%20Theory/data_evaluation/bin_entropy_dev.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m EvaluatorBIN()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ac140439/Documents/SimTech/Projects/Information%20Theory/data_evaluation/bin_entropy_dev.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mdata_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata.hdf5\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ac140439\\Documents\\SimTech\\Projects\\Information Theory\\data_evaluation\\evaluators\\bin_evaluators.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbase_evaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m Evaluator\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munite_toolbox\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbin_estimators\u001b[39;00m \u001b[39mimport\u001b[39;00m estimate_ideal_bins, calc_qs_entropy\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munite_toolbox\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbin_estimators\u001b[39;00m \u001b[39mimport\u001b[39;00m calc_bin_entropy, calc_bin_mutual_information, calc_bin_kld\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'base_evaluator'"
     ]
    }
   ],
   "source": [
    "from evaluators.bin_evaluators import EvaluatorBIN\n",
    "\n",
    "eval = EvaluatorBIN()\n",
    "\n",
    "eval.data_path = \"data.hdf5\"\n",
    "eval.out_path = \"results/bin.hdf5\"\n",
    "eval.logger = get_logger(\"results/bin_entropy.log\")\n",
    "\n",
    "eval.quantity = \"h\"\n",
    "\n",
    "eval.hyper_params = [\"scott\", \"fd\", \"sturges\"]\n",
    "eval.sample_sizes = [100, 200, 500, 1_000, 5_000, 10_000, 50_000, 100_000]\n",
    "eval.seeds = range(1, 6)\n",
    "\n",
    "for k, v in vars(eval).items():\n",
    "    print(f\"{k} - {v}\")\n",
    "\n",
    "eval.create_database()\n",
    "eval.create_group()\n",
    "\n",
    "experiments = [\n",
    "    \"uniform\",\n",
    "    \"normal\",\n",
    "    \"normal-mixture\",\n",
    "    \"exponential\",\n",
    "    \"bivariate-normal\",\n",
    "    \"bivariate-normal-mixture\",\n",
    "    \"gexp\",\n",
    "    \"4d-gaussian\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.hyper_params.append(\"qs\")\n",
    "\n",
    "# # # # # UNIFORM # # # # #\n",
    "\n",
    "experiment = \"uniform\"\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "true_h = np.log(dist_params[0][1]) # Reference\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # NORMAL # # # # #\n",
    "\n",
    "experiment = \"normal\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "true_h = 0.5 * np.log(2 * np.pi * (dist_params[0][1]**2)) + 0.5 # Reference\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # NORMAL-MIXTURE # # # # #\n",
    "\n",
    "experiment = \"normal-mixture\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "def pdf_normal(x, params):\n",
    "    y = 0.0\n",
    "    for dist in params:\n",
    "        l, s, w = dist\n",
    "        y += stats.norm(loc=l, scale=s).pdf(x) * w\n",
    "    return y\n",
    "\n",
    "def h_normal(x, params):\n",
    "    p = pdf_normal(x, params)\n",
    "    return -1 * p * np.log(p)\n",
    "\n",
    "norm_lims = [[-15, 25]]\n",
    "\n",
    "true_h = nquad(h_normal, norm_lims, args=(dist_params,))[0] # Numerical Integration Result\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # EXPONENTIAL # # # # #\n",
    "\n",
    "experiment = \"exponential\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "true_h = 1 - np.log(1/dist_params[0][1]) # Reference\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.hyper_params = [\"scott\", \"fd\", \"sturges\"]\n",
    "\n",
    "# # # # # BIVARIATE-NORMAL # # # # #\n",
    "\n",
    "experiment = \"bivariate-normal\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "d = len(dist_params[0][1])\n",
    "true_h = 0.5 * np.log((2 * np.pi * np.exp(1)) ** d * np.linalg.det(dist_params[0][1])) # Reference\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # BIVARIATE-NORMAL-MIXTURE # # # # #\n",
    "\n",
    "experiment = \"bivariate-normal-mixture\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "def pdf_mnorm(x, y, params):\n",
    "    z = 0.0\n",
    "    for dist in params:\n",
    "        l, s, w = dist\n",
    "        z += stats.multivariate_normal(mean=l, cov=s).pdf(np.dstack((x, y))) * w\n",
    "    return z\n",
    "\n",
    "def h_mnorm(x, y, params1):\n",
    "    p = pdf_mnorm(x, y, params1)\n",
    "    return -1 * p * np.log(p)\n",
    "\n",
    "binorm_lims = [[-7, 7], [-7, 7]]\n",
    "\n",
    "true_h = nquad(h_mnorm, binorm_lims, args=(dist_params,))[0] # Numerical Integration Result\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # GAMMA-EXPONENTIAL # # # # #\n",
    "\n",
    "experiment = \"gexp\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "tetha = dist_params[0][0]\n",
    "true_h = 1 +  tetha - tetha * digamma(tetha) + np.log(gamma(tetha)) - np.log(1.0) # Reference\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.seeds = range(1, 2)\n",
    "\n",
    "# # # # # 4D-GAUSSIAN # # # # #\n",
    "\n",
    "experiment = \"4d-gaussian\"\n",
    "\n",
    "# Calculate Truth\n",
    "with h5py.File(eval.data_path, \"r\") as f:\n",
    "    dist_params = ast.literal_eval(f[experiment][\"p\"].attrs[\"hyper_params\"])\n",
    "\n",
    "d = len(dist_params[0][1])\n",
    "true_h = 0.5 * np.log((2 * np.pi * np.exp(1)) ** d * np.linalg.det(dist_params[0][1])) # Reference\n",
    "\n",
    "eval.evaluate_entropy(experiment, calc_bin_entropy, \"scott\")\n",
    "\n",
    "# Save\n",
    "eval.write_to_hdf5(experiment, true_h)\n",
    "print(f\"True entropy: {true_h:.3f} nats\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
